# Birdscanner v2.2
# Last modified: mÃ¥n jun 10, 2024  04:15
# Sign: JN
# Thanks to John Sundh
# TODO: test locally and on slurm
# TODO: define temp() files and folders
# TODO: add log directives to process commands?

from glob import glob

# Input files
configfile: "config/config.yaml"
REFERENCES, = glob_wildcards("data/references/{ref}.fas")
GENOMES, = glob_wildcards("data/genomes/{genome}.gz")

# Local rules are run on the submit node on a cluster
#localrules: all, OO8_get_scaffold_ids, OO9_get_reference_ids, O10_select_scaffolds, ...
localrules: all

# Helper function gather_chunk_hmm_lists
def gather_chunk_hmm_lists(wildcards):
    """
    Gather chunk lists of hmms
    """
    input = []
    ck_output_folder = checkpoints.split_list_of_hmms.get(genome=wildcards.genome).output[0]
    f = f"{ck_output_folder}/{wildcards.genome}.{wildcards.n}.txt"
    with open(f, 'r') as fhin:
        for line in fhin:
            input.append(line.strip())
    return input

# Helper function gather_hmmer_out
def gather_hmmer_out(wildcards):
    """
    Gather list of .hmmer.out files (run/hmmer/genome/genome.n.hmmer.out)
    """
    input = []
    ck_output_folder = checkpoints.split_list_of_hmms.get(genome=wildcards.genome).output[0]
    n = glob_wildcards(os.path.join(ck_output_folder, "{genome}.{n}.hmm")).n
    input = expand("run/hmmer/{genome}/{genome}.{n}.hmmer.out",
                   n=n, genome=wildcards.genome)
    return input

# 0. Rule for final output
rule all:
    """
    TODO: Figure out which lines that should be kept
    """
    input:
        expand("results/genomes/{genome}", genome=GENOMES),
        expand("results/hmmer/{genome}.hmmer.out.gz", genome=GENOMES),
        "run/tmp/genes.done"

# 17. compress_hmmer_out
# TODO: This rule has the same input as O15_parse_hmmer. Problem?
rule O17_compress_hmmer_out:
    """
    Compress (and keep) hmmer output.
    """
    input:
        "run/hmmer/{genome}.hmmer.out"
    output:
        "results/hmmer/{genome}.hmmer.out.gz"
    threads:
        config["pigz"]["threads"]
    conda:
        "envs/pigz.yaml"
    shell:
        """
        pigz \
          -p {threads} \
          -c {input} > {output}
        """

# 16. gather_genes
rule O16_gather_genes:
    """
    Gather genes from parsed nhmmer output in genome folders.
    """
    input:
        expand("results/genomes/{genome}", genome=GENOMES)
    output:
        dir = directory("results/genes"),
        file = touch("run/tmp/genes.done")
        #file = temp(touch("run/tmp/genes.done"))
    conda:
        "envs/perl.yaml"
    shell:
        """
        perl workflow/scripts/bs2-gather-genes.pl \
          --outdir={output.dir} \
          $(find results/genomes -type d)
        """

# 15. parse_hmmer
rule O15_parse_hmmer:
    """
    Parse hmmer output.
    """
    input:
        hmmer = "run/hmmer/{genome}.hmmer.out",
        fas = "run/plast/{genome}.plast.fas"
    output:
        directory("results/genomes/{genome}")
    params:
        prefix = "{genome}",
        fastaheader = "{genome}",
        stats = config["parsehmmer"]["stats"]
    conda:
        "envs/perl.yaml"
    shell:
        """
        perl workflow/scripts/bs2-parse-nhmmer.pl \
          -f {params.fastaheader} \
          -p {params.prefix} \
          -i {input.hmmer} \
          -g {input.fas} \
          -d {output} \
          {params.stats}
        """

# 14. concatenate_hmmer_out
rule O14_concatenate_hmmer_out:
    """
    Concatenate run/hmmer/genome/genome.n.hmmer.out to
    run/hmmer/genome.hmmer.out
    """
    input:
        gather_hmmer_out
    output:
        "run/hmmer/{genome}.hmmer.out"
    shell:
        """
        cat {input} > {output}
        """

# 13. run_hmmer
rule O13_run_hmmer:
    """
    Run HMMer: the selected scaffolds against the selected hmms.
    """
    input:
        #"run/tmp/{genome}.{n}.hmmpress.done",
        hmm = "run/hmmer/{genome}/{genome}.{n}.hmm",
        query = "run/plast/{genome}.plast.fas"
    output:
        "run/hmmer/{genome}.{n}.hmmer.out"
        #temp("run/hmmer/{genome}.{n}.hmmer.out")
    params:
        hmmerprog = config["type"]["hmmerprog"],
        outfmt = config["hmmer"]["outfmt"],
        chunks = config["split"]["chunks"]
    threads:
        config["hmmer"]["threads"]
    conda:
        "envs/hmmer.yaml"
    shell:
        """
        {params.hmmerprog} \
          {params.outfmt} \
          --cpu {threads} \
          --tblout {output} \
          {input.hmm} \
          {input.query} > /dev/null
        """

# 12. run_hmmpress
rule O12_run_hmmpress:
    """
    Run hmmpress.
    """
    input:
        "run/hmmer/{genome}/{genome}.{n}.hmm"
    output:
        expand("run/hmmer/{{genome}}/{{genome}}.{{n}}.hmm.h3{s}",
               s=["f","i","m","p"])
    log:
        "logs/hmmer/{genome}.{n}.log"
    conda:
        "envs/hmmer.yaml"
    shell:
        """
        hmmpress \
          {input} > {log} 2>&1
        """

# 11. split_list_of_hmms
# TODO: BUG: Wildcards in this rule is "genome=Apa.hmmer.out". I was aiming for "genome=Apa".
checkpoint O11_split_list_of_hmms:
    """
    Split the list of hmm files in chunks.
    Input: a file run/tmp/Apa.ref.ids with file paths
    Output: run/hmmer/Apa/Apa.00.txt, ..., run/hmmer/Apa/Apa.N.txt.
            N files according to int chunks.
            txt files contain paths of files.
    """
    input:
        "run/tmp/{genome}.ref.ids"
    output:
        directory(expand("run/hmmer/{genome}", genome=GENOMES))
        #directory("run/hmmer/{genome}")
    params:
        chunks = config["split"]["chunks"]
    shell:
        """
        mkdir {output}
        n_lines_refids=$(wc -l < {input})
        split \
          -d \
          --number=l/{params.chunks} \
          --elide-empty-files \
          --additional-suffix='.txt' \
          {input} \
          'run/hmmer/{wildcards.genome}/{wildcards.genome}.'
        """

# 10. select_scaffolds
rule O10_select_scaffolds:
    """
    Extract the scaffolds with best plast hits from the splitted genome fasta.
    """
    input:
        db = "run/plast/{genome}.split.fas",
        idfile = "run/tmp/{genome}.scaffolds.ids"
    output:
        "run/plast/{genome}.plast.fas"
        #temp("run/plast/{genome}.plast.fas")
    params:
        dbtype = config["type"]["dbtype"],
        outfmt = config["blastdbcmd"]["outfmt"]
    conda:
        "envs/blast.yaml"
    shell:
        """
        blastdbcmd \
          -db {input.db} \
          -dbtype {params.dbtype} \
          -entry_batch {input.idfile} \
          -outfmt {params.outfmt} \
          -out {output}
        """

# 9. get_reference_ids
# TODO: BUG: Wildcards in this rule is "genome=Apa.hmmer.out". I was aiming for "genome=Apa".
rule OO9_get_reference_ids:
    """
    Get IDs (file names) for those reference gene files that have a best plast hit
    with length above minlen.
    NOTE: Room here for more filtering if needed.
    NOTE: The awk step is dependent on finding the '__', which was introduced in
    rule convert_fas, to work.
    """
    input:
        "run/plast/{genome}.plast.tab"
    output:
        expand("run/tmp/{genome}.ref.ids", genome=GENOMES)
        #"run/tmp/{genome}.ref.ids"
        #temp("run/tmp/{genome}.ref.ids")
    params:
        minlen = config["lengthfilter"]["min"]
    shell:
        """
        awk '$4>{params.minlen}' {input} | \
          sort -t$'\t' -k1g -k12rg | \
          awk -F $'\t' '!x[$1]++' | \
          awk -F $'__' '{{print $1 ".hmm"}}' | \
          sort -u > {output}
        """

# 8. get_scaffold_ids
rule OO8_get_scaffold_ids:
    """
    The idea is that for each species, we would expect one best hit, and we wish to
    see which of the scaffolds that most often provides the best hit.  We wish to
    search with hmms only against the scaffolds having sufficiently long hits in
    the plast search.

    Plast outfmt 1:
    query ID, subject ID, percent identities, alignment length, nb. misses,
    nb. gaps, query begin, query end, subject begin, subject end, e-value, bit score

    We will extract hits where ('alignment length' > minlen), and then we first
    sort the table on query ID, then sort the table on 'bit score' in descending
    order, and finally go down the list and keep unique 'subject ID'. Note: There
    is room here to include a scaffold only if having some bit score or e-value.

    """
    input:
        "run/plast/{genome}.plast.tab"
    output:
        "run/tmp/{genome}.scaffolds.ids"
        #temp("run/tmp/{genome}.scaffolds.ids")
    params:
        minlen = config["lengthfilter"]["min"]
    shell:
        """
        awk '$4>{params.minlen}' {input} | \
          sort -t$'\t' -k1,1 -k12rg | \
          awk -F $'\t' '!x[$1]++' | \
          awk -F $'\t' '{{print $2}}' | \
          sort -u > {output}
        """

# 7. run_plast
# TODO: BUG: Wildcards in this rule is "genome=Apa.hmmer.out". I was aiming for "genome=Apa".
rule OO7_run_plast:
    """
    Run plast with all concatenated reference sequences as query,
    and the splitted genome fasta as data base.
    """
    input:
        db_done = "run/tmp/{genome}.makeblastdb.done",
        query = "run/tmp/reference.fas"
    output:
        expand("run/plast/{genome}.plast.tab", genome=GENOMES)
        #"run/plast/{genome}.plast.tab"
        #temp("run/plast/{genome}.plast.tab")
    threads:
        config["plast"]["threads"]
    params:
        maxhitperquery = config["plast"]["maxhitperquery"],
        bargraph = config["plast"]["bargraph"],
        plastprog = config["type"]["plastprog"]
    shell:
        """
        plast \
          -p {params.plastprog} \
          -i {input.query} \
          -d run/plast/{wildcards.genome}.split.fas \
          -o {output} \
          -a {threads} \
          -max-hit-per-query {params.maxhitperquery} \
          {params.bargraph}
        """

# 6. make_genome_plast_db
# TODO: BUG: Wildcards in this rule is "genome=Apa.hmmer.out". I was aiming for "genome=Apa".
rule OO6_make_genome_plast_db:
    """
    Make plast database.
    """
    input:
        "run/plast/{genome}.split.fas",
    output:
        touch("run/tmp/{genome}.makeblastdb.done")
        #temp(touch("run/tmp/{genome}.makeblastdb.done"))
    params:
        dbtype = config["type"]["dbtype"],
        parse_seqids = config["makeblastdb"]["parseseqids"]
    conda:
        "envs/blast.yaml"
    shell:
        """
        makeblastdb \
          -in {input} \
          -dbtype {params.dbtype} \
          {params.parse_seqids}
        """

# 5. split_genome_fasta
# TODO: BUG: output is now run/plast/Apa.hmmer.out.split.fas. Wildcards in this rule is "genome=Apa.hmmer.out". I was aiming for "genome=Apa".
rule OO5_split_genome_fasta:
    """
    Split fasta sequences longer than length=100,000.
    Note that 100,000 is the maximum length for plast.
    """
    input:
        "data/genomes/{genome}.gz"
    output:
        expand("run/plast/{genome}.split.fas", genome=GENOMES)
        #"run/plast/{genome}.split.fas"
        #temp("run/plast/{genome}.split.fas")
    threads:
        config["pigz"]["threads"]
    params:
        length = config["splitfast"]["max"]
    conda:
        "envs/pigz.yaml"
    shell:
        """
        splitfast \
          -m {params.length} \
          <(pigz -p {threads} -d -c {input}) > {output}
        """

# 4. cat_reference_fas
rule OO4_cat_reference_fas:
    """
    Concatenate all reference fasta files to one (reference.fas).
    """
    input:
        expand("run/tmp/{ref}.fasta", ref=REFERENCES)
    output:
        "run/tmp/reference.fas"
        #temp("run/tmp/reference.fas")
    shell:
        """
        find \
          run/tmp \
          -type f \
          -name '*.fasta' \
          -exec cat {{}} \\+ > {output}
        """

# 3. create_hmms
rule OO3_create_hmms:
    """
    Create hmms from Stockholm format.
    """
    input:
        "run/tmp/{ref}.sto"
    output:
        "run/tmp/{ref}.hmm"
        #temp("run/tmp/{ref}.hmm")
    params:
        hmmbuildtype = config["type"]["hmmbuildtype"]
    conda:
        "envs/hmmer.yaml"
    shell:
        """
        hmmbuild \
          {params.hmmbuildtype} \
          {output} \
          {input}
        """

# 2. fasta_to_stockholm
rule OO2_fasta_to_stockholm:
    """
    Fasta to Stockholm MSA conversion.
    """
    input:
        "data/references/{ref}.fas"
    output:
        "run/tmp/{ref}.sto"
        #temp("run/tmp/{ref}.sto")
    conda:
        "envs/perl.yaml"
    shell:
        """
        perl workflow/scripts/bs2-fas-to-sto.pl \
          {input} > {output}
        """

# 1. Convert fasta
rule OO1_convert_fas:
    """
    Relabel fasta headers to '>filename__i', where i is an iterator.
    The '__' is important and used later in rule get_reference_ids.
    """
    input:
        "data/references/{ref}.fas"
    output:
        "run/tmp/{ref}.fasta"
        #temp("run/tmp/{ref}.fasta")
    shell:
        """
        awk -v a=$(basename {input} .fas) \
          '/>/{{$0=\">\"a\"__\"++i}}1' \
          {input} > {output}
        """

# Helper rule clean
rule clean:
    """
    Remove run directory.
    """
    shell:
        """
        rm -rf run/
        """

# Helper rule distclean
rule distclean:
    """
    Remove run and results directories.
    """
    shell:
        """
        rm -rf run/ results/
        """

# On success, remove files
onsuccess:
    """
    Remove run directory on succesful finish.
    """
    shell("rm -r run ; find ./results -type f -name .snakemake_timestamp -exec rm {{}} +")

